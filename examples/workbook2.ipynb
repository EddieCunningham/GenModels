{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd\n",
    "import autograd.numpy as anp\n",
    "import itertools\n",
    "from functools import partial, namedtuple\n",
    "from autograd.extend import primitive, defvjp\n",
    "from autograd import jacobian as jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp( v, axis=0 ):\n",
    "    max_v = anp.max( v )\n",
    "    return anp.log( anp.sum( anp.exp( v - max_v ), axis=axis ) ) + max_v\n",
    "\n",
    "def logsumexp_vjp(ans, x):\n",
    "    x_shape = x.shape\n",
    "    return lambda g: anp.full(x_shape, g) * anp.exp(x - np.full(x_shape, ans))\n",
    "defvjp(logsumexp, logsumexp_vjp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbelSample( shape, eps=1e-8 ):\n",
    "    u = anp.random.random( shape )\n",
    "    return -anp.log( -anp.log( u + eps ) + eps )\n",
    "def gumbelSoftmaxSample( logits, g=None, temp=1.0 ):\n",
    "    if( g is None ):\n",
    "        g = gumbelSample( logits.shape )\n",
    "    y = logits + g\n",
    "    ans = anp.exp( y ) / temp\n",
    "    return ans / ans.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphas_unrolled( theta ):\n",
    "    T, K = theta.L.shape\n",
    "    a_0 = theta.pi0 + theta.L[ 0 ]\n",
    "    a_1 = logsumexp( a_0[ :, None ] + theta.pi, axis=0 ) + theta.L[ 1 ]\n",
    "    a_2 = logsumexp( a_1[ :, None ] + theta.pi, axis=0 ) + theta.L[ 2 ]\n",
    "    return anp.array( [ a_0, a_1, a_2 ] )\n",
    "\n",
    "def betas_unrolled( theta ):\n",
    "    T, K = theta.L.shape\n",
    "    b_2 = anp.zeros( K )\n",
    "    b_1 = logsumexp( b_2 + theta.pi + theta.L[ 2 ], axis=1 )\n",
    "    b_0 = logsumexp( b_1 + theta.pi + theta.L[ 1 ], axis=1 )\n",
    "    return anp.array( [ b_0, b_1, b_2 ] )    \n",
    "\n",
    "def joints_unrolled( alpha, beta ):\n",
    "    j_1 = alpha[ 0 ][ :, None ] + pi + L[ 1 ] + beta[ 1 ]\n",
    "    j_2 = alpha[ 1 ][ :, None ] + pi + L[ 2 ] + beta[ 2 ]\n",
    "    return anp.array( [ j_1, j_2 ] )\n",
    "\n",
    "def predictive_unrolled( alpha, beta ):\n",
    "    T, d_latent = alpha.shape\n",
    "    joint = joints_unrolled( alpha, beta )\n",
    "    return joint - anp.reshape( ( alpha + beta )[ :-1 ], ( T-1, d_latent, 1 ) )\n",
    "    \n",
    "def alphas( theta ):\n",
    "    T, K = theta.L.shape\n",
    "    alpha = anp.zeros( ( T, K ) )\n",
    "    alpha[ 0 ] = theta.pi0 + theta.L[ 0 ]\n",
    "    for t in range( 1, T ):\n",
    "        alpha[ t ] = logsumexp( alpha[ t - 1 ][ :, None ] + theta.pi, axis=0 ) + theta.L[ t ]\n",
    "    return alpha\n",
    "\n",
    "def betas( theta ):\n",
    "    T, K = theta.L.shape\n",
    "    beta = anp.zeros( ( T, K ) )\n",
    "    for t in reversed( range( 0, T - 1 ) ):\n",
    "        beta[ t ] = logsumexp( beta[ t + 1 ] + theta.pi + theta.L[ t + 1 ], axis=1 )\n",
    "    return beta\n",
    "\n",
    "def joints( alpha, beta ):\n",
    "    joints = anp.zeros( ( T-1, d_latent, d_latent ) )\n",
    "    for t in range( T - 1 ):\n",
    "        joints[ t ] = alpha[ t ][ :, None ] + pi + L[ t + 1 ] + beta[ t + 1 ]\n",
    "    return joints\n",
    "\n",
    "def predictive( alpha, beta ):\n",
    "    T, d_latent = alpha.shape\n",
    "    joint = joints( alpha, beta )\n",
    "    return joint - anp.reshape( ( alpha + beta )[ :-1 ], ( T-1, d_latent, 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleX( alpha, beta ):\n",
    "    T, K = alpha.shape\n",
    "    log_z = logsumexp( alpha[ -1 ] )\n",
    "    \n",
    "    preds = predictive( alpha, beta )\n",
    "    x_samples = anp.zeros( ( T, K ) )\n",
    "    \n",
    "    x_samples[ 0 ] = alpha[ 0 ] + beta[ 0 ] - log_z\n",
    "    \n",
    "    for t, p in enumerate( preds ):\n",
    "        logits = logsumexp( p + x_samples[ t ], axis=1 )\n",
    "        x_samples[ t + 1 ] = anp.log( gumbelSoftmaxSample( logits ) )\n",
    "        \n",
    "    return x_samples\n",
    "\n",
    "def sampleX_unrolled( alpha, beta, gumb ):\n",
    "    T, K = alpha.shape\n",
    "    log_z = logsumexp( alpha[ -1 ] )\n",
    "        \n",
    "    preds = predictive_unrolled( alpha, beta )\n",
    "    \n",
    "    x_0 = alpha[ 0 ] + beta[ 0 ] - log_z\n",
    "    \n",
    "    logits = anp.log( anp.exp( preds[ 0 ] ) @ anp.exp( x_0 ) )\n",
    "    x_1 = anp.log( gumbelSoftmaxSample( logits, g=gumb[ 1 ] ) )\n",
    "    \n",
    "    logits = anp.log( anp.exp( preds[ 1 ] ) @ anp.exp( x_1 ) )\n",
    "    x_2 = anp.log( gumbelSoftmaxSample( logits, g=gumb[ 1 ] ) )\n",
    "    \n",
    "    return anp.array( [ x_0, x_1, x_2 ] )\n",
    "\n",
    "def hmmSamples( theta ):\n",
    "    alpha, beta = alphas( theta ), betas( theta )\n",
    "    return sampleX( alpha, beta )\n",
    "\n",
    "def hmmSamples_unrolled( theta, gumb ):\n",
    "    alpha, beta = alphas_unrolled( theta ), betas_unrolled( theta )\n",
    "    return sampleX_unrolled( alpha, beta, gumb )\n",
    "\n",
    "def neuralNet( x_samples, theta ):\n",
    "    \n",
    "    N = theta.d_latent * theta.d_obs\n",
    "    W = anp.arange( N ).reshape( ( theta.d_latent, theta.d_obs ) )\n",
    "    \n",
    "    y_dist = anp.einsum( 'ij,ti->tj', W, x_samples )\n",
    "    probs = y_dist[ anp.arange( theta.T ), theta.y ]\n",
    "    return anp.sum( probs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = namedtuple( 'Theta', [ 'pi0', 'pi', 'L', 'T', 'd_latent', 'd_obs', 'y' ] )\n",
    "T = 3\n",
    "d_latent = 3\n",
    "d_obs = 2\n",
    "y = np.random.choice( d_obs, size=T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi0 = np.random.random( d_latent )\n",
    "pi = np.random.random( ( d_latent, d_latent ) )\n",
    "pi0 = np.log( pi0 )\n",
    "pi = np.log( pi )\n",
    "L = np.random.random( ( d_latent, d_obs ) )\n",
    "L = L.T[ y ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumb = gumbelSample( ( T, d_latent ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4662907 , -0.6942795 ,  2.16057019],\n",
       "       [-0.3437912 ,  0.46290751, -0.1191163 ],\n",
       "       [ 0.03566366, -0.10849283,  0.07282917]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trueAnswer( L ):\n",
    "    theta = Theta( pi0, pi, L, T, d_latent, d_obs, y )\n",
    "    x_samples = hmmSamples_unrolled( theta, gumb )\n",
    "    return neuralNet( x_samples, theta )\n",
    "jac( trueAnswer )( L )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a( L ):\n",
    "    theta = Theta( pi0, pi, L, T, d_latent, d_obs, y )\n",
    "    x_samples = hmmSamples_unrolled( theta, gumb )\n",
    "    return x_samples\n",
    "def b( x_samples ):\n",
    "    theta = Theta( pi0, pi, L, T, d_latent, d_obs, y )\n",
    "    return neuralNet( x_samples, theta )\n",
    "da = jac( a )( L )\n",
    "db = jac( b )( a( L ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13000478, -1.38964251,  2.51964729],\n",
       "       [-0.83208038,  1.29573408, -0.46365371],\n",
       "       [-0.08749182,  0.13307068, -0.04557886]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum( 'ijab,ij->ab', da, db )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Compute x samples\n",
    "## Step 2 - Compute dlogP( y | x )/dx\n",
    "## Step 3 - Accumulate dlogP( y | x )/dL by computing dx/dL and summing immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv( theta, gumb ):\n",
    "    temp = 1.0\n",
    "    \n",
    "    # Get the needed stats\n",
    "    alpha, beta = alphas( theta ), betas( theta )\n",
    "    preds = predictive( alpha, beta )\n",
    "    log_z = logsumexp( alpha[ -1 ] )\n",
    "    \n",
    "    T, K = alpha.shape\n",
    "    \n",
    "    # Initialize the variables\n",
    "    dXtdLs = np.zeros( ( T, T, K, K ) )\n",
    "    dXtdXt1 = np.zeros( ( T-1, K, K ) )\n",
    "    x_samples = np.zeros( ( T, K ) )\n",
    "    \n",
    "    # Base case derivative\n",
    "    x_samples[ 0 ] = alpha[ 0 ] + beta[ 0 ] - log_z\n",
    "    dXtdLs[ 0, 0 ] = np.eye( K ) - np.exp( x_samples[ 0 ] )\n",
    "\n",
    "    print( '\\nt', 0, 's', 0, 'dXtdLs[ t, t ]\\n', dXtdLs[ 0, 0 ] )\n",
    "    \n",
    "    for i, p in enumerate( preds ):\n",
    "        t = i + 1\n",
    "        \n",
    "        # Compute x_t | x_t-1\n",
    "        p = theta.pi + theta.L[ t ] + beta[ t ] - beta[ t - 1 ][ :, None ]\n",
    "        logits = logsumexp( p + x_samples[ t - 1 ], axis=1 )\n",
    "        unnormx = logits + gumb[ t ] - np.log( temp )\n",
    "        x_samples[ t ] = unnormx - logsumexp( unnormx )\n",
    "        \n",
    "        # Compute dLogit / dL_t\n",
    "        dXPdLt = np.eye( K ) - np.exp( theta.L[ t ] + theta.pi + beta[ t ] ).T\n",
    "        \n",
    "        # Compute dLogit / dX_t-1\n",
    "        dLogitdXt1 = np.exp( p + x_samples[ t - 1 ] - logits[ :, None ] )\n",
    "        dLogitdP = dLogitdXt1\n",
    "        \n",
    "        # Compute dX_t / dLogit\n",
    "        dXtdLogit = np.eye( K ) - np.exp( x_samples[ t ] )\n",
    "        \n",
    "        # Compute dX_t / dX_t-1\n",
    "        dXtdXt1[ i ] = dXtdLogit @ dLogitdXt1\n",
    "    \n",
    "        # Compute the derivative dX_t / dL_s for s == t\n",
    "        dXtdLs[ t, t ] = dXtdLogit @ dLogitdP @ dXPdLt\n",
    "        \n",
    "        # Update each of the L derivatives\n",
    "        for s in reversed( range( t ) ):\n",
    "            # Compute dX_t / dL_s for s < t\n",
    "            dXtdLs[ t, s ] = dXtdXt1[ i ] @ dXtdLs[ t-1, s ]\n",
    "        \n",
    "    return dXtdLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "t 0 s 0 dXtdLs[ t, t ]\n",
      " [[ 0.75561822 -0.44904658 -0.30657163]\n",
      " [-0.24438178  0.55095342 -0.30657163]\n",
      " [-0.24438178 -0.44904658  0.69342837]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.75561822, -0.44904658, -0.30657163],\n",
       "         [-0.24438178,  0.55095342, -0.30657163],\n",
       "         [-0.24438178, -0.44904658,  0.69342837]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.08986504, -0.10107791,  0.01121287],\n",
       "         [ 0.12682073, -0.30038841,  0.17356768],\n",
       "         [-0.02320787,  0.05281617, -0.0296083 ]],\n",
       "\n",
       "        [[ 0.15352277, -0.2211536 ,  0.40992592],\n",
       "         [ 0.14916173, -1.0293167 ,  0.92114144],\n",
       "         [-0.02821793,  0.17856803, -0.16388745]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]]],\n",
       "\n",
       "\n",
       "       [[[-0.00797907,  0.0194045 , -0.01142542],\n",
       "         [-0.02253939,  0.05361719, -0.03107781],\n",
       "         [ 0.00141751, -0.00339818,  0.00198067]],\n",
       "\n",
       "        [[-0.00916851,  0.06705772, -0.05905207],\n",
       "         [-0.02641145,  0.18398361, -0.16421125],\n",
       "         [ 0.00164982, -0.01168981,  0.01038416]],\n",
       "\n",
       "        [[ 0.02006404, -0.10100966,  0.1192764 ],\n",
       "         [ 0.04046547, -0.27908717,  0.32072313],\n",
       "         [-0.00289946,  0.0176885 , -0.02052493]]]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = Theta( pi0, pi, L, T, d_latent, d_obs, y )\n",
    "deriv( theta, gumb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 7.55618217e-01, -4.49046583e-01, -3.06571634e-01],\n",
       "         [-2.44381783e-01,  5.50953417e-01, -3.06571634e-01],\n",
       "         [-2.44381783e-01, -4.49046583e-01,  6.93428366e-01]],\n",
       "\n",
       "        [[ 3.26463435e-02,  2.52806087e-02, -5.79269522e-02],\n",
       "         [ 6.21143449e-02, -1.40845923e-01,  7.87315777e-02],\n",
       "         [-1.17004974e-01,  1.86149838e-01, -6.91448646e-02]],\n",
       "\n",
       "        [[ 8.91936531e-03, -1.43948637e-02,  5.47549836e-03],\n",
       "         [-1.66117260e-02,  4.00088512e-02, -2.33971252e-02],\n",
       "         [ 1.72217774e-02, -4.71276331e-02,  2.99058558e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 8.98650435e-02, -1.01077910e-01,  1.12128664e-02],\n",
       "         [ 1.26820735e-01, -3.00388411e-01,  1.73567676e-01],\n",
       "         [-2.32078695e-02,  5.28161663e-02, -2.96082968e-02]],\n",
       "\n",
       "        [[-1.26362414e-01,  1.30269462e-01, -3.90704849e-03],\n",
       "         [-1.86000309e-01,  3.55624649e-01, -1.69624341e-01],\n",
       "         [ 3.39327950e-02, -6.27325253e-02,  2.87997303e-02]],\n",
       "\n",
       "        [[ 2.40068934e-04, -4.40108480e-03,  4.16101587e-03],\n",
       "         [ 1.79387302e-03, -9.95520683e-03,  8.16133381e-03],\n",
       "         [-3.08403645e-04,  1.77064611e-03, -1.46224246e-03]]],\n",
       "\n",
       "\n",
       "       [[[-4.41128145e-03,  1.09307713e-02, -6.51948985e-03],\n",
       "         [-1.89715952e-02,  4.51434661e-02, -2.61718709e-02],\n",
       "         [ 4.98530102e-03, -1.18719069e-02,  6.88660590e-03]],\n",
       "\n",
       "        [[ 6.49321491e-03, -1.28950033e-02,  6.40178839e-03],\n",
       "         [ 2.78345724e-02, -5.34249087e-02,  2.55903363e-02],\n",
       "         [-7.31473790e-03,  1.40489027e-02, -6.73416476e-03]],\n",
       "\n",
       "        [[-9.75639176e-02,  9.04297227e-02,  7.13419491e-03],\n",
       "         [-1.39922719e-01,  2.83554655e-01, -1.43631937e-01],\n",
       "         [ 3.81525715e-02, -7.50330805e-02,  3.68805091e-02]]]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.transpose( 0, 2, 1, 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = alphas( theta ), betas( theta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forAG( func ):\n",
    "    def wrapper( _L ):\n",
    "        theta = Theta( pi0, pi, _L, T, d_latent, d_obs, y )\n",
    "        return func( theta )\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_unrolled( theta ):\n",
    "    beta = betas_unrolled( theta )\n",
    "    p1 = theta.pi + theta.L[ 1 ] + beta[ 1 ] - beta[ 0 ][ :, None ]\n",
    "    p2 = theta.pi + theta.L[ 2 ] + beta[ 2 ] - beta[ 1 ][ :, None ]\n",
    "    return anp.array( [ p1, p2 ] )\n",
    "@forAG\n",
    "def pred_unrolled_ag( theta ):\n",
    "    return pred_unrolled( theta )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jac( pred_unrolled_ag )( L ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mypred_jac( theta ):\n",
    "    preds = pred_unrolled( theta )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d*beta*<sup>(t)</sup>/d*L*<sup>(s)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betas_unrolled( theta ):\n",
    "    T, K = theta.L.shape\n",
    "    b_2 = anp.zeros( K )\n",
    "    b_1 = logsumexp( b_2 + theta.pi + theta.L[ 2 ], axis=1 )\n",
    "    b_0 = logsumexp( b_1 + theta.pi + theta.L[ 1 ], axis=1 )\n",
    "    return anp.array( [ b_0, b_1, b_2 ] )    \n",
    "\n",
    "@forAG\n",
    "def betas_unrolled_ag( theta ):\n",
    "    return betas_unrolled( theta )\n",
    "\n",
    "def dbetadL( theta ):\n",
    "    betas = betas_unrolled( theta )\n",
    "    T, K = betas.shape\n",
    "    betas_jac = np.zeros( ( T, K, T, K ) )\n",
    "    for t in range( T-2, -1, -1 ):\n",
    "        val = np.exp( theta.pi + theta.L[ t+1 ] + betas[ t+1 ] - betas[ t ][ :, None ] )\n",
    "        betas_jac[ t, :, t+1, : ] = val\n",
    "        for s in range( t+2, T ):\n",
    "            betas_jac[ t, :, s, : ] = val @ betas_jac[ t+1, :, s, : ]\n",
    "    return betas_jac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d*F<sup>(t)</sup>*/d*L<sup>(s)</sup>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_unrolled( theta ):\n",
    "    beta = betas_unrolled( theta )\n",
    "    f1 = theta.pi + theta.L[ 1 ] + beta[ 1 ] - beta[ 0 ][ :, None ]\n",
    "    f2 = theta.pi + theta.L[ 2 ] + beta[ 2 ] - beta[ 1 ][ :, None ]\n",
    "    return anp.array( [ f1, f2 ] )\n",
    "\n",
    "@forAG\n",
    "def F_unrolled_ag( theta ):\n",
    "    return F_unrolled( theta )\n",
    "\n",
    "def dFdL( theta ):\n",
    "    F = F_unrolled( theta )\n",
    "    T, K = theta.L.shape\n",
    "    f_jac = np.zeros( F.shape + theta.L.shape )\n",
    "    b_jac = dbetadL( theta )\n",
    "    for t in range( 1, T ):\n",
    "        val = np.eye( K ) - np.exp( F[ t-1 ] )\n",
    "        for s in range( T ):\n",
    "            \n",
    "            f_jac[ t-1, :, :, s, : ] = b_jac[ t, :, s, : ] - b_jac[ t-1, :, s, : ][ :, None, : ]\n",
    "            if( t == s ):\n",
    "                f_jac[ t-1, :, :, s, : ] += np.eye( K )\n",
    "            \n",
    "    return f_jac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d*H<sup>(t)</sup>*/d*L<sup>(s)</sup>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_samples_unrolled( theta, gumb, temp=1.0 ):\n",
    "    F = F_unrolled( theta )\n",
    "    T, K = theta.T, theta.d_latent\n",
    "    x_samples = anp.zeros( ( T, K ) )\n",
    "    \n",
    "    alpha, beta = alphas_unrolled( theta ), betas_unrolled( theta )\n",
    "    log_z = logsumexp( alpha[ -1 ] )\n",
    "    x_samples_0 = theta.pi0 + theta.L[ 0 ] + beta[ 0 ] - log_z\n",
    "    \n",
    "    H0 = logsumexp( F[ 0 ] + x_samples_0, axis=1 )\n",
    "    G = H0 + gumb[ 1 ] - anp.log( temp )\n",
    "    x_samples_1 = G - logsumexp( G )\n",
    "\n",
    "    H1 = logsumexp( F[ 1 ] + x_samples_1, axis=1 )\n",
    "    G = H1 + gumb[ 2 ] - anp.log( temp )\n",
    "    x_samples_2 = G - logsumexp( G )\n",
    "\n",
    "    return anp.array( [ x_samples_0, x_samples_1, x_samples_2 ] )\n",
    "\n",
    "@forAG\n",
    "def x_samples_unrolled_ag( theta ):\n",
    "    return x_samples_unrolled( theta, gumb )\n",
    "\n",
    "def dHdL( theta, gumb, temp=1.0 ):\n",
    "    F = F_unrolled( theta )\n",
    "    dF = dFdL( theta )\n",
    "    dB = dbetadL( theta )\n",
    "    \n",
    "    T, K = theta.T, theta.d_latent\n",
    "    x_samples = anp.zeros( ( T, K ) )\n",
    "    dX = np.zeros( ( T, K, T, K ) )\n",
    "    \n",
    "    alpha, beta = alphas_unrolled( theta ), betas_unrolled( theta )\n",
    "    log_z = logsumexp( alpha[ -1 ] )\n",
    "    x_samples[ 0 ] = theta.pi0 + theta.L[ 0 ] + beta[ 0 ] - log_z\n",
    "    \n",
    "    dX[ 0 ] = dB[ 0 ]\n",
    "    dX[ 0, :, :, : ] -= np.exp( alpha + beta - log_z )\n",
    "    dX[ 0, :, 0, : ] += np.eye( K )\n",
    "    \n",
    "    for t in range( 1, T ):\n",
    "        H = logsumexp( F[ t-1 ] + x_samples[ t-1 ], axis=1 )\n",
    "        G = H + gumb[ t ] - anp.log( temp )\n",
    "        x_samples[ t ] = G - logsumexp( G )\n",
    "        \n",
    "        # H are the logits\n",
    "        # F are the conditioned transition matrix\n",
    "        # G are the unnormalized x samples\n",
    "\n",
    "        for s in range( T ):\n",
    "            deriv = dF[ t-1, :, :, s, : ] + dX[ t-1, :, s, : ][ None, :, : ]\n",
    "            val = np.exp( F[ t-1 ] + x_samples[ t-1 ] - H[ :, None ] )\n",
    "            dH = np.einsum( 'ij,ijk->ijk', val, deriv )\n",
    "            tmp = 1 - np.exp( G - logsumexp( G ) )\n",
    "            dX[ t, :, s, : ] = np.einsum( 'i,ijk->ik', tmp, dH )\n",
    "        \n",
    "    return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.75561822, -0.44904658, -0.30657163],\n",
       "         [ 0.03264634,  0.02528061, -0.05792695],\n",
       "         [ 0.00891937, -0.01439486,  0.0054755 ]],\n",
       "\n",
       "        [[-0.24438178,  0.55095342, -0.30657163],\n",
       "         [ 0.06211434, -0.14084592,  0.07873158],\n",
       "         [-0.01661173,  0.04000885, -0.02339713]],\n",
       "\n",
       "        [[-0.24438178, -0.44904658,  0.69342837],\n",
       "         [-0.11700497,  0.18614984, -0.06914486],\n",
       "         [ 0.01722178, -0.04712763,  0.02990586]]],\n",
       "\n",
       "\n",
       "       [[[-0.02791065,  0.00398982,  0.02392082],\n",
       "         [-0.03125553,  0.04752293, -0.0162674 ],\n",
       "         [ 0.00420886, -0.0118033 ,  0.00759444]],\n",
       "\n",
       "        [[-0.0310497 , -0.18078   ,  0.21182971],\n",
       "         [-0.09592882,  0.13779689, -0.04186807],\n",
       "         [ 0.01148529, -0.0333516 ,  0.02186631]],\n",
       "\n",
       "        [[-0.11751182,  0.10545616,  0.01205566],\n",
       "         [-0.01968889,  0.05098026, -0.03129136],\n",
       "         [ 0.00639153, -0.01494169,  0.00855016]]],\n",
       "\n",
       "\n",
       "       [[[-0.05785748,  0.03102342,  0.02683406],\n",
       "         [-0.02560338,  0.04650705, -0.02090367],\n",
       "         [ 0.21801203, -0.31572969,  0.09771766]],\n",
       "\n",
       "        [[-0.03400883,  0.02316878,  0.01084005],\n",
       "         [-0.01243746,  0.0237843 , -0.01134683],\n",
       "         [ 0.08951567, -0.10266009,  0.01314442]],\n",
       "\n",
       "        [[-0.05876369,  0.02764662,  0.03111707],\n",
       "         [-0.02380927,  0.04445161, -0.02064234],\n",
       "         [ 0.12474277, -0.33514799,  0.21040522]]]])"
      ]
     },
     "execution_count": 1300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dHdL( theta, gumb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 7.55618217e-01, -4.49046583e-01, -3.06571634e-01],\n",
       "         [ 3.26463435e-02,  2.52806087e-02, -5.79269522e-02],\n",
       "         [ 8.91936531e-03, -1.43948637e-02,  5.47549836e-03]],\n",
       "\n",
       "        [[-2.44381783e-01,  5.50953417e-01, -3.06571634e-01],\n",
       "         [ 6.21143449e-02, -1.40845923e-01,  7.87315777e-02],\n",
       "         [-1.66117260e-02,  4.00088512e-02, -2.33971252e-02]],\n",
       "\n",
       "        [[-2.44381783e-01, -4.49046583e-01,  6.93428366e-01],\n",
       "         [-1.17004974e-01,  1.86149838e-01, -6.91448646e-02],\n",
       "         [ 1.72217774e-02, -4.71276331e-02,  2.99058558e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 3.86093376e-02, -4.57825240e-02,  7.17318646e-03],\n",
       "         [-1.57952071e-02,  1.27514407e-02,  3.04376643e-03],\n",
       "         [ 1.24872450e-04, -1.94678441e-03,  1.82191196e-03]],\n",
       "\n",
       "        [[ 7.55650288e-02, -2.45093025e-01,  1.69527996e-01],\n",
       "         [-3.84774105e-02,  3.87961262e-02, -3.18715660e-04],\n",
       "         [ 1.67867654e-03, -7.50090644e-03,  5.82222991e-03]],\n",
       "\n",
       "        [[-7.44635755e-02,  1.08111552e-01, -3.36479767e-02],\n",
       "         [ 3.14270887e-02, -2.63564708e-02, -5.07061793e-03],\n",
       "         [-4.23600129e-04,  4.22494650e-03, -3.80134637e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 8.78564797e-03, -1.21050167e-02,  3.31936878e-03],\n",
       "         [-3.67630346e-03,  3.05178197e-03,  6.24521496e-04],\n",
       "         [ 5.99629743e-02, -5.61713384e-02, -3.79163596e-03]],\n",
       "\n",
       "        [[ 2.56594041e-04,  5.50425859e-03, -5.76085263e-03],\n",
       "         [ 1.77573012e-04, -4.32246861e-04,  2.54673849e-04],\n",
       "         [-4.28438918e-03,  9.61529065e-02, -9.18685173e-02]],\n",
       "\n",
       "        [[-5.44908789e-03, -3.46420868e-03,  8.91329657e-03],\n",
       "         [ 1.74642101e-03, -9.16219403e-04, -8.30201603e-04],\n",
       "         [-2.58853772e-02, -1.48334871e-01,  1.74220248e-01]]]])"
      ]
     },
     "execution_count": 1296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac( x_samples_unrolled_ag )( L )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 1243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones( 4 )[ None, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbelSample( shape, eps=1e-8 ):\n",
    "    u = anp.random.random( shape )\n",
    "    return -anp.log( -anp.log( u + eps ) + eps )\n",
    "gumb = gumbelSample( ( T, d_latent ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation( x ):\n",
    "    return anp.sin( x )\n",
    "\n",
    "def check( x ):\n",
    "    d_in = x.shape[ -1 ]\n",
    "    d_out = 100\n",
    "    W1 = anp.arange( d_in * d_out ).reshape( ( d_in, d_out ) )\n",
    "    b1 = anp.arange( d_out )\n",
    "    \n",
    "    d_in = 100\n",
    "    d_out = 1\n",
    "    W2 = anp.arange( d_in * d_out ).reshape( ( d_in, d_out ) )\n",
    "    b2 = anp.arange( d_out )\n",
    "    \n",
    "    z = activation( anp.einsum( 'ij,ti->tj', W1, x ) + b1 )\n",
    "    \n",
    "    return anp.sum( activation( anp.einsum( 'ij,ti->tj', W2, z + b2 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random( ( 10, 3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2740183982017976"
      ]
     },
     "execution_count": 1335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 µs ± 1.26 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "jac( check )( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60521847, 0.02983659, 0.33941179],\n",
       "       [0.77536835, 0.88879314, 0.19546331],\n",
       "       [0.60456678, 0.443581  , 0.8629852 ],\n",
       "       [0.00963859, 0.16892713, 0.72825752],\n",
       "       [0.79318225, 0.98739385, 0.26031268],\n",
       "       [0.22024778, 0.12707345, 0.38055451],\n",
       "       [0.99660973, 0.55210765, 0.07690179],\n",
       "       [0.23970282, 0.62977837, 0.90661498],\n",
       "       [0.87995858, 0.89019672, 0.84628363],\n",
       "       [0.32152712, 0.35871458, 0.8535235 ]])"
      ]
     },
     "execution_count": 1337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asdf( x ):\n",
    "    return anp.sum( x**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.21043693, 0.05967318, 0.67882357],\n",
       "       [1.5507367 , 1.77758628, 0.39092662],\n",
       "       [1.20913355, 0.887162  , 1.72597039],\n",
       "       [0.01927718, 0.33785425, 1.45651504],\n",
       "       [1.58636451, 1.9747877 , 0.52062536],\n",
       "       [0.44049555, 0.2541469 , 0.76110901],\n",
       "       [1.99321946, 1.10421531, 0.15380357],\n",
       "       [0.47940564, 1.25955675, 1.81322995],\n",
       "       [1.75991717, 1.78039344, 1.69256726],\n",
       "       [0.64305424, 0.71742917, 1.70704699]])"
      ]
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac( asdf )( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.21043693, 0.05967318, 0.67882357],\n",
       "       [1.5507367 , 1.77758628, 0.39092662],\n",
       "       [1.20913355, 0.887162  , 1.72597039],\n",
       "       [0.01927718, 0.33785425, 1.45651504],\n",
       "       [1.58636451, 1.9747877 , 0.52062536],\n",
       "       [0.44049555, 0.2541469 , 0.76110901],\n",
       "       [1.99321946, 1.10421531, 0.15380357],\n",
       "       [0.47940564, 1.25955675, 1.81322995],\n",
       "       [1.75991717, 1.78039344, 1.69256726],\n",
       "       [0.64305424, 0.71742917, 1.70704699]])"
      ]
     },
     "execution_count": 1347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd( theta ):\n",
    "    T, K = theta.L.shape\n",
    "    alpha = []\n",
    "    alpha.append( theta.pi0 + theta.L[ 0 ] )\n",
    "    for t in range( 1, T ):\n",
    "        alpha.append( logsumexp( alpha[ -1 ][ :, None ] + theta.pi, axis=0 ) + theta.L[ t ] )\n",
    "    return anp.array( alpha )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [],
   "source": [
    "@forAG\n",
    "def fwdAG( theta ):\n",
    "    return fwd( theta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 1.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.28211374, 0.58096008, 0.13692618],\n",
       "         [1.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.26349003, 0.25343247, 0.4830775 ],\n",
       "         [0.        , 1.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.21395349, 0.52503869, 0.26100783],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.25767243, 0.40356353, 0.33876404],\n",
       "         [0.27519173, 0.50390694, 0.22090133],\n",
       "         [1.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.23656793, 0.48895239, 0.27447968],\n",
       "         [0.20460717, 0.17498943, 0.62040341],\n",
       "         [0.        , 1.        , 0.        ]],\n",
       "\n",
       "        [[0.24785029, 0.42181305, 0.33033666],\n",
       "         [0.19232064, 0.4196534 , 0.38802595],\n",
       "         [0.        , 0.        , 1.        ]]]])"
      ]
     },
     "execution_count": 1350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac( fwdAG )( L )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [],
   "source": [
    "@forAG\n",
    "def blah( theta ):\n",
    "    return alphas_unrolled( theta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 1.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.28211374, 0.58096008, 0.13692618],\n",
       "         [1.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.26349003, 0.25343247, 0.4830775 ],\n",
       "         [0.        , 1.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.21395349, 0.52503869, 0.26100783],\n",
       "         [0.        , 0.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.25767243, 0.40356353, 0.33876404],\n",
       "         [0.27519173, 0.50390694, 0.22090133],\n",
       "         [1.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.23656793, 0.48895239, 0.27447968],\n",
       "         [0.20460717, 0.17498943, 0.62040341],\n",
       "         [0.        , 1.        , 0.        ]],\n",
       "\n",
       "        [[0.24785029, 0.42181305, 0.33033666],\n",
       "         [0.19232064, 0.4196534 , 0.38802595],\n",
       "         [0.        , 0.        , 1.        ]]]])"
      ]
     },
     "execution_count": 1352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac( blah )( L )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonFBSMultiplyTerms( terms ):\n",
    "    # Basically np.einsum but in log space\n",
    "    terms = list( terms )\n",
    "\n",
    "    # Separate out where the feedback set axes start and get the largest fbs_axis.\n",
    "    # Need to handle case where ndim of term > all fbs axes\n",
    "    # terms, fbs_axes_start = list( zip( *terms ) )\n",
    "    fbs_axes_start = [ -1, -1 ]\n",
    "\n",
    "    if( max( fbs_axes_start ) != -1 ):\n",
    "        max_fbs_axis = max( [ ax if ax != -1 else term.ndim for ax, term in zip( fbs_axes_start, terms ) ] )\n",
    "\n",
    "        if( max_fbs_axis > 0 ):\n",
    "            # Pad extra dims at each term so that the fbs axes start the same way for every term\n",
    "            for i, ax in enumerate( fbs_axes_start ):\n",
    "                if( ax == -1 ):\n",
    "                    for _ in range( max_fbs_axis - terms[ i ].ndim + 1 ):\n",
    "                        terms[ i ] = terms[ i ][ ..., None ]\n",
    "                else:\n",
    "                    for _ in range( max_fbs_axis - ax ):\n",
    "                        terms[ i ] = anp.expand_dims( terms[ i ], axis=ax )\n",
    "    else:\n",
    "        max_fbs_axis = -1\n",
    "\n",
    "    ndim = max( [ len( term.shape ) for term in terms ] )\n",
    "\n",
    "    axes = [ [ i for i, s in enumerate( t.shape ) if s != 1 ] for t in terms ]\n",
    "\n",
    "    # Get the shape of the output\n",
    "    shape = anp.ones( ndim, dtype=int )\n",
    "    for ax, term in zip( axes, terms ):\n",
    "        shape[ anp.array( ax ) ] = term.squeeze().shape\n",
    "\n",
    "    total_elts = shape.prod()\n",
    "    if( total_elts > 1e8 ):\n",
    "        assert 0, 'Don\\'t do this on a cpu!  Too many terms: %d'%( int( total_elts ) )\n",
    "\n",
    "    # Basically np.einsum in log space\n",
    "    ans = anp.zeros( shape )\n",
    "    for ax, term in zip( axes, terms ):\n",
    "\n",
    "        for _ in range( ndim - term.ndim ):\n",
    "            term = term[ ..., None ]\n",
    "\n",
    "        ans += term\n",
    "#         ans += np.broadcast_to( term, ans.shape )\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blah( x ):\n",
    "    y = np.random.random( ( 1, 4, 2, 1, 1, 1, 8 ) )\n",
    "    return nonFBSMultiplyTerms( ( x, y ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random( ( 3, 1, 2, 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [],
   "source": [
    "Something = recordclass.recordclass( 'something', [ 'a', 'b' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blah2( s ):\n",
    "    s.a *= 4\n",
    "    return ( s.a * s.b )**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blahh( a ):\n",
    "    s = Something( a, 5 )\n",
    "    return blah2( s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 1431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blahh( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2400.)"
      ]
     },
     "execution_count": 1432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac( blahh )( 3.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blah3( a ):\n",
    "    a *= 4\n",
    "    return ( a*5 )**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2400.)"
      ]
     },
     "execution_count": 1429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac( blah3 )( 3.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600.0"
      ]
     },
     "execution_count": 1430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah3( 3.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tester():\n",
    "    def __init__( self ):\n",
    "        self.a = 4\n",
    "        \n",
    "    def blah( self, b ):\n",
    "        self.b = b\n",
    "        self.stuff()\n",
    "        return self.c\n",
    "        \n",
    "    def stuff( self ):\n",
    "        self.b *= 4\n",
    "        self.c = ( self.b * 3 )**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1434,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829.4399999999998"
      ]
     },
     "execution_count": 1435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.blah( 2.4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blah4( b ):\n",
    "    t = tester()\n",
    "    return t.blah( b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829.4399999999998"
      ]
     },
     "execution_count": 1438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah4( 2.4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(691.2)"
      ]
     },
     "execution_count": 1439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac( blah4 )( 2.4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordclass import recordclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [],
   "source": [
    "Succ = recordclass( 'Succ', [ 'a', 'b' ] )\n",
    "class blahh( Succ ):\n",
    "    @property\n",
    "    def yo( self ):\n",
    "        return self.a*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = blahh( 3, 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah.yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd.misc.optimizers import adam\n",
    "from autograd import grad\n",
    "import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blah( params, iter ):\n",
    "    a, b, c = params\n",
    "    return np.sum( np.sum( a )*np.sum( b ) + c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random( ( 4, 3 ) )\n",
    "b = np.random.random( ( 4, 3 ) )\n",
    "c = np.random.random( ( 4, 3 ) )\n",
    "params = ( a, b, c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = grad( blah )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[85.06240416, 85.06240416, 85.06240416],\n",
       "        [85.06240416, 85.06240416, 85.06240416],\n",
       "        [85.06240416, 85.06240416, 85.06240416],\n",
       "        [85.06240416, 85.06240416, 85.06240416]]),\n",
       " array([[91.70995451, 91.70995451, 91.70995451],\n",
       "        [91.70995451, 91.70995451, 91.70995451],\n",
       "        [91.70995451, 91.70995451, 91.70995451],\n",
       "        [91.70995451, 91.70995451, 91.70995451]]),\n",
       " array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]]))"
      ]
     },
     "execution_count": 1481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g( params, 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blah( a, b ):\n",
    "    print( a, b )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1485,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = partial( blah, b=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n"
     ]
    }
   ],
   "source": [
    "k( 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4\n"
     ]
    }
   ],
   "source": [
    "k( 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "letters = string.ascii_lowercase[ :10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghij,a,b,c,d,e,f,g,h,i->j'"
      ]
     },
     "execution_count": 1490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters + ',' + ','.join( [ i for i in letters[ :-1 ] ] ) + '->' + letters[ -1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import value_and_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = None\n",
    "def blah( a ):\n",
    "    global t\n",
    "    b = np.sum( a, axis=0 )\n",
    "    def blah2( b ):\n",
    "        c = np.linalg.cholesky( b )\n",
    "        d = np.sum( c )\n",
    "        return d\n",
    "    val, t = value_and_grad( blah2 )( b )\n",
    "    return val\n",
    "\n",
    "def blahh( a ):\n",
    "    b = np.sum( a, axis=0 )\n",
    "    c = np.linalg.cholesky( b )\n",
    "    d = np.sum( c )\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "a = scipy.stats.invwishart.rvs( scale=np.eye( 4 ), df=5, size=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60.326246428875415,\n",
       " array([[[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "         [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "         [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "         [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       " \n",
       "        [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "         [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "         [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "         [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       " \n",
       "        [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "         [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "         [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "         [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       " \n",
       "        [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "         [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "         [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "         [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       " \n",
       "        [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "         [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "         [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "         [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]]]))"
      ]
     },
     "execution_count": 1530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_and_grad( blah )( a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "       [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "       [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "       [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]])"
      ]
     },
     "execution_count": 1531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t._value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "        [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "        [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "        [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       "\n",
       "       [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "        [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "        [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "        [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       "\n",
       "       [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "        [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "        [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "        [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       "\n",
       "       [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "        [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "        [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "        [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]],\n",
       "\n",
       "       [[ 0.02395243, -0.1135541 , -0.05461702, -0.05644718],\n",
       "        [-0.1135541 ,  0.79227359,  0.40746491,  0.4258389 ],\n",
       "        [-0.05461702,  0.40746491,  0.21296255,  0.21281433],\n",
       "        [-0.05644718,  0.4258389 ,  0.21281433,  0.22582264]]])"
      ]
     },
     "execution_count": 1532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad( blahh )( a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GenModel]",
   "language": "python",
   "name": "conda-env-GenModel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
